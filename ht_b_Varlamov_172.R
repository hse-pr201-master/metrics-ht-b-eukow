# Фиксируем seed для воспроизводимости результатов 
set.seed(10)

# Подключаем необходимые библиотеки
library(tidyverse)
library(lmtest)
library(mctest)
library(car)
library(caret)
library(sandwich)
library(forecast)

# Устанавливаем рабочую директорию
# setwd("~/Documents/Studies/Econometrics/HW/B")



### Часть 1

# Загружаем данные:
data = read_csv('country_profile_variables.csv', col_names = T, 
                na = c('...', '-99', '~0', '-~0.0', '~0.0', '.../...'))

# В качестве missing data мы интерпретируем '...', '-99' и пр. после ознакомления с файлом.
# Здесь также сбиты столбцы, поскольку Mobile-cellular subscriptions присутствует дважды
# и последний столбец с Net Official Development Assist. received содержит только NA ('-99').
# Поэтому необходимо быть аккуратным(-ой) при выборе переменных.



## Задание 1

# Исследовательский вопрос: есть ли взаимосвязь между государственными расходами на здравоохранение 
# и младенческой смертностью? В качестве зависимой переменной возьмем младенческую смертность.
# В качестве независимой -- государственные расходы на здравоохранение.

# Выдвинем две гипотезы:

# H1: Гос. расходы на здравоохранение снижают младенческую смертность в стране при прочих равных.

# H2: Данное влияние гос. расходов обусловлено уровнем жизни в стране, выраженном посредством ВВП. 
# (Здесь в модель также должна включаться переменная взаимодействия, см. далее.)



## Задание 2 

X = select(data, infant_mortality = 'Infant mortality rate (per 1000 live births',
           health_expenditure = 'Health: Total expenditure (% of GDP)',
           gdp_per_capita = 'GDP per capita (current US$)',
           fertility = 'Fertility rate, total (live births per woman)',
           physicians = 'Health: Physicians (per 1000 pop.)',
           industry = 'Economy: Industry (% of GVA)',
           agriculture = 'Economy: Agriculture (% of GVA)',
           region = 'Region')

X = mutate(X, log_gdp_per_capita = log(X$gdp_per_capita + 1),
           modernised = as.numeric(X$industry > X$agriculture),
           region = factor(X$region))

X = subset(X, select = -c(industry, agriculture))

# В качестве контрольных переменных берем:

# (c) log_gdp_per_capita -- ВВП на душу населения в логарифмах:
        # показывает уровень жизни в стране, который может уменьшать младенческую смертность 
        # необходимость логарифмирования будет показана дальше на основе гистограмм

# (a) fertility -- показатель фертильности населения:
        # сложно предсказать характер взаимодействия, однако оно наверняка имеет место 

# (a) physicians -- количество докторов в стране на 1 000 человек населения
        # чем больше в стране докторов на душу населения, тем меньше должна быть смертность

# (b) modernised -- дамми-переменная, которая показывает, можно ли считать страну модернизованной:
        # в качестве эмпирического свидетельства этого факта возьмем то, больше ли в стране
        # индустриальный сектор по сравнению с сектором сельского хозяйства; 
        # вероятнее всего, в модернизированных странах уровень смертности ниже

# Помимо этого, у нас есть (z) независимая переменная гос. расходов на здравоохранение
# и (d) переменная взаимодействия между гос. расходами на здравоохранение и log_gdp_per_capita,
# которая выявляет совместный эффект: отрицательный коэффициент будет говорить о том,
# что эффект от вложений в здравоохранение в богатых странах сильнее, чем в бедных, 
# положительный - что эффект от вложений в бедных странах сильнее, чем в богатых. 
# Необходимо помнить, что высокий ВВП на душу населения может быть не только в развитых странах,
# но и, например, в таких странах, как ОАЭ или Кувейт. 

# Переменная region -- факторная переменная региона, в котором находится страна, для задания 6.



## Задание 3

# infant_mortality:
summary(X$infant_mortality) # 25 пропущенных значений
# Поскольку это зависимая переменная, то мы удалим все наблюдения с отсутствующим значением:
X = filter(X, !is.na(X$infant_mortality))
summary(X$infant_mortality)
# Построим гистограмму:
hist(X$infant_mortality, col = 'black', border = 'white', 
     xlab = 'Значение переменной infant_mortality', ylab = 'Частота появления', 
     main = 'Распределение переменной infant_mortality')
# Построим "ящик с усами":
boxplot(X$infant_mortality, horizontal = T, col = 'orange', notch = T, 
        xlab = 'Значение переменной infant_mortality', ylab = 'Размах',
        main = 'Диаграмма размаха переменной infant_mortality')
# Из этих графиков видно, что для данной переменной, скорее всего, требуется лог-трансформация:
X = mutate(X, log_infant_mortality = log(X$infant_mortality + 1))
X = subset(X, select = -infant_mortality)
summary(X$log_infant_mortality)
# Построим гистограмму:
hist(X$log_infant_mortality, col = 'black', border = 'white', 
     xlab = 'Значение переменной log_infant_mortality', ylab = 'Частота появления', 
     main = 'Распределение переменной log_infant_mortality')
# Построим "ящик с усами":
boxplot(X$log_infant_mortality, horizontal = T, col = 'orange', notch = T, 
        xlab = 'Значение переменной log_infant_mortality', ylab = 'Размах',
        main = 'Диаграмма размаха переменной log_infant_mortality')
# Теперь данные симметричны и без выбросов.

# health_expenditure:
summary(X$health_expenditure) # 20 пропущенных значений
# Поскольку это независимая переменная, то мы удалим все наблюдения с отсутствующим значением:
X = filter(X, !is.na(X$health_expenditure))
summary(X$health_expenditure)
# Построим гистограмму:
hist(X$health_expenditure, col = 'black', border = 'white', 
     xlab = 'Значение переменной health_expenditure', ylab = 'Частота появления', 
     main = 'Распределение переменной health_expenditure')
# Построим "ящик с усами":
boxplot(X$health_expenditure, horizontal = T, col = 'orange', notch = T, 
        xlab = 'Значение переменной health_expenditure', ylab = 'Размах',
        main = 'Диаграмма размаха переменной health_expenditure')
# Есть один несильный выброс, который не должен исказить результаты исследования. 

# gdp_per_capita и log_gdp_per_capita:
summary(X$gdp_per_capita) # 1 пропущенное значение
# Поскольку данная переменная достаточно важная, то мы удалим это наблюдение:
X = filter(X, !is.na(X$gdp_per_capita))
summary(X$gdp_per_capita)
# Построим гистограмму:
hist(X$gdp_per_capita, col = 'black', border = 'white', 
     xlab = 'Значение переменной gdp_per_capita', ylab = 'Частота появления', 
     main = 'Распределение переменной gdp_per_capita')
# Построим "ящик с усами":
boxplot(X$gdp_per_capita, horizontal = T, col = 'orange', notch = T, 
        xlab = 'Значение переменной gdp_per_capita', ylab = 'Размах',
        main = 'Диаграмма размаха переменной gdp_per_capita')
# Отсюда видно, что лог-трансформация необходима, поскольку данные сильно разбросаны и несимметричны:
X = subset(X, select = -gdp_per_capita)
summary(X$log_gdp_per_capita)
# Построим гистограмму:
hist(X$log_gdp_per_capita, col = 'black', border = 'white', 
     xlab = 'Значение переменной log_gdp_per_capita', ylab = 'Частота появления', 
     main = 'Распределение переменной log_gdp_per_capita')
# Построим "ящик с усами":
boxplot(X$log_gdp_per_capita, horizontal = T, col = 'orange', notch = T, 
        xlab = 'Значение переменной log_gdp_per_capita', ylab = 'Размах',
        main = 'Диаграмма размаха переменной log_gdp_per_capita')
# Теперь данные симметричны и без выбросов.

# fertility:
summary(X$fertility) # без пропущенных значений
# Построим гистограмму:
hist(X$fertility, col = 'black', border = 'white', 
     xlab = 'Значение переменной fertility', ylab = 'Частота появления', 
     main = 'Распределение переменной fertility')
# Построим "ящик с усами":
boxplot(X$fertility, horizontal = T, col = 'orange', notch = T, 
        xlab = 'Значение переменной fertility', ylab = 'Размах',
        main = 'Диаграмма размаха переменной fertility')
# Данные немного несимметричны и есть один несильный выброс, 
# однако эта переменная не требует лог-трансформации.

# physicians:
summary(X$physicians) # 67 пропущенных значений
# Заменим их нулями, поскольку, вероятно, это свидетельствует о малом количестве докторов в стране
X[is.na(X$physicians), 'physicians'] = 0
# Построим гистограмму:
hist(X$physicians, col = 'black', border = 'white', 
     xlab = 'Значение переменной physicians', ylab = 'Частота появления', 
     main = 'Распределение переменной physicians')
# Построим "ящик с усами":
boxplot(X$physicians, horizontal = T, col = 'orange', notch = T, 
        xlab = 'Значение переменной physicians', ylab = 'Размах',
        main = 'Диаграмма размаха переменной physicians')
# После добавления нулей эту переменную необходимо лог-трансформировать:
X = mutate(X, log_physicians = log(X$physicians + 1))
X = subset(X, select = -physicians)
summary(X$log_physicians)
# Построим гистограмму:
hist(X$log_physicians, col = 'black', border = 'white', 
     xlab = 'Значение переменной log_physicians', ylab = 'Частота появления', 
     main = 'Распределение переменной log_physicians')
# Построим "ящик с усами":
boxplot(X$log_physicians, horizontal = T, col = 'orange', notch = T, 
        xlab = 'Значение переменной log_physicians', ylab = 'Размах',
        main = 'Диаграмма размаха переменной log_physicians')
# Тоже есть смещенность в сторону нуля, но уже лучше :)

# modernised:
summary(X$modernised) # 1 пропущенное значение, которое мы удалим:
X = filter(X, !is.na(X$modernised))
summary(X$modernised)
# Здесь строить гистограмму или диаграмму размаха бесполезно.

# region:
summary(X$region) # без пропущенных значений
# Здесь строить гистограмму или диаграмму размаха невозможно.



## Задание 4

# Специфицируем LS-модель:
model_LS = lm(data = X, log_infant_mortality ~ health_expenditure + log_gdp_per_capita + 
                      health_expenditure:log_gdp_per_capita + log_physicians + 
                      fertility + modernised)

# (a) Мультиколлинеарность:

vif(lm(data = X, log_infant_mortality ~ health_expenditure + log_gdp_per_capita + 
               log_physicians + fertility + modernised)) # без переменной взаимодействия
# Коэффициенты вздутия дисперсии не превышают 10, мультиколлинеарность не выявлена.

cor(subset(X, select = -c(region, log_infant_mortality)))
# Нет значений выборочной корреляции между регрессорами, больших чем 0.9, 
# мультиколлинеарность не выявлена.

omcdiag(model_LS) # 5 тестов, включая CN < 30, из 6 не выявили мультиколлинеарность.

# (b) Гетероскедастичность:

# Тест Бройша-Пагана:
bptest(model_LS) # p-value = 0.4905 => нет оснований отвергать гипотезу H0 о гомоскедастичности 
        # на любом разумном уровне значимости => гетероскедастичность этим тестом не выявлена 

# Тест Голдфельда-Квандта:
gqtest(model_LS, order.by = ~ health_expenditure, data = X, fraction = 0.2) # p-value = 0.881
gqtest(model_LS, order.by = ~ log_gdp_per_capita, data = X, fraction = 0.2) # p-value = 0.04816
gqtest(model_LS, order.by = ~ log_physicians, data = X, fraction = 0.2) # p-value = 0.4224
gqtest(model_LS, order.by = ~ fertility, data = X, fraction = 0.2) # p-value = 0.2579
# Тест выявил возможность проблемы гетероскедастичности по переменной log_gdp_per_capita,
# поскольку p-value = 0.04816 и гипотеза H0 об условной гомоскедастичности может быть отвергнута.

# Визуально для переменной log_gdp_per_capita:
plot(X$log_gdp_per_capita, model_LS$residuals**2, 
     xlab = 'Значение регрессора log_gdp_per_capita', 
     ylab = 'Остатки регрессии в квадрате', 
     main = 'Визуализация проблемы гетероскедастичности по регрессору log_gdp_per_capita')
# Как видно, с ростом значений log_gdp_per_capita разброс остатков действительно увеличивается,
# а следовательно, существует проблема гетероскедастичности, тем более что эта переменная
# носит своего рода характер "размера".

# Отсюда: стандартные ошибки могут оказаться несостоятельными. 
# Решение: использование робастной ковариационной матрицы (в задании 5b).

# (c) Эндогенность:

# Стандартных тестов на эндогенность как таковых нет, однако можно провести RESET-тест Рамсея,
# который показывает, есть ли пропущенные переменные в регрессии или нет. Ведь одна из причин 
# возникновения проблемы эндогенности (все остальные, по сути, являются порождением этой) -- 
# невключение существенных переменных. 

resettest(model_LS)
# p-value = 6.697e-08 => на любом разумном уровне значимости отвергается гипотеза H0 
# о верной спецификации модели => есть вероятность наличия пропущенных переменных,
# что приводит к проблеме эндогенности.

# К сожалению, чтобы решить данную проблему или провести еще один тест (например, Хаусмана
# на сравнение LS- и IV-регрессий), необходимо наличие и хорошее обоснование инструментальных
# переменных, что в рамках данного датасета представляется почти невозможным. 

# Проблема эндогенности приводит к тому, что коэффициенты смещаются и становятся несостоятельными.



## Задание 5

summary(model_LS)

# Оценка робастной ковариационной матрицы:
HC3 = vcovHC(model_LS, type = 'HC3')
# Использование HC3:
coeftest(model_LS, vcov. = HC3)

# При использовании устойчивой к гетероскедастичности ковариационной матрицы сами коэффициенты 
# МНК-регрессии не меняются -- меняются лишь стандартные ошибки и, соответственно, значимость 
# коэффициентов. Если изначально мы бы могли принять гипотезы H1 и H2 на уровне значимости 10%,
# то при использовании робастных ошибок мы вынуждены отвергнуть эти гипотезы (коэффициенты при 
# health_expenditure и переменной взаимодействия оказались совершенно незначимы). Таким образом,
# взаимосвязи между гос. расходами на здравоохранение и младенческой смертностью нет. Однако
# мы все еще можем проинтерпретировать остальные коэффициенты регрессии :) 

# Адекватность регрессии в целом: 
# p-value < 2.2e-16 для F-теста по всей регрессии, а значит, 
# мы отвергаем гипотезу H0 о незначимости регрессии в целом;
# кроме того, модель обладает хорошей объясняющей способностью 
# (Adjusted R-squared = 0.8537).

# Комментируем коэффициенты: в плане значимости, банальным образом и по смыслу...

# Коэффициент при log_gdp_per_capita = -0.250853 (значим на уровне 0.001):
# С ростом ВВП на душу населения на 1% уровень младенческой смертности падает на 0.25%.
# По смыслу: чем богаче страна, тем меньше смертность из-за того, что, вероятно, люди могут 
# позволить себе более продвинутые медицинские услуги, в т.ч. для новорожденных; 
# кроме того, богатство страны позволяет улучшать медицину в стране в целом. 

# Коэффициент при log_physicians = -0.286742 (значим на уровне 0.001):
# С ростом относительного количества докторов на 1% уровень младенческой смертности падает на 0.28%.
# По смыслу: чем больше в стране докторов, тем меньше смертность, поскольку на каждого младенца
# приходится больше докторов, которые могут спасти ему или ей жизнь.

# Коэффициент при fertility = 0.2556282 (значим на уровне 0.001):
# С ростом уровня фертильности на 1 младенческая смертность растет на 25.56%.
# По смыслу: сложно сказать, но чем выше уровень фертильности (количество новорожденных 
# на 1 женщину) в стране, тем выше смертность, вероятно, из-за того, что система здравоохранения
# может не справляться с большим количеством новорожденных; кроме того, могут существовать
# биологические причины (например, женщины рождают больше, но в более позднем возрасте и т.д.).

# Коэффициент при modernised = 0.222200 (значим на уровне 0.05):
# Факт модернизированности страны увеличивает младенческую смертность на 22.22%. 
# По смыслу: это самый противоречивый вывод из модели, но и наименее достоверный (значимость 
# коэффициента здесь не особо большая по сравнению с остальными). Если попытаться найти этому 
# объяснение, то можно, например, сказать, что при прочих равных такой эффект имеет место 
# вследствие менее выгодных экологических условий в более развитых (индустриально) странах, что 
# влияет на здоровье младенцев. В принципе можно еще найти более хорошие критерии модернизованности.



# Задание 6 

# Деление выборки:
ind = createDataPartition(y = X$log_infant_mortality, p = 0.8, list = FALSE)
train = X[ind,]
test = X[-ind,]

# Базовая спецификация:
pred = predict(model_LS, test)
mse0 = mean((test$log_infant_mortality - pred)^2) # 0.06036462

# Первая попытка -- убираем "плохие" переменные:
model1 = lm(data = X, log_infant_mortality ~ log_gdp_per_capita + log_physicians + fertility)
pred1 = predict(model1, test)
mse1 = mean((test$log_infant_mortality - pred1)^2) # 0.08124423 -- неудачно

# Вторая попытка -- добавляем факторную переменную регионов в 1-ю попытку:
model2 = lm(data = X, log_infant_mortality ~ log_gdp_per_capita + log_physicians 
            + fertility + region)
pred2 = predict(model2, test)
mse2 = mean((test$log_infant_mortality - pred2)^2) # 0.06144608 -- лучше 1-й попытки, хуже базы

# Третья попытка -- добавим факторную переменную регионов в базовую модель
model3 = lm(data = X, log_infant_mortality ~ health_expenditure + log_gdp_per_capita +
                    health_expenditure:log_gdp_per_capita + log_physicians + 
                    fertility + modernised + region)
pred3 = predict(model3, test)
mse3 = mean((test$log_infant_mortality - pred3)^2) # 0.04596366 -- лучше базовой спецификации!



### Часть 2



## Задание 1

# AR(1):
y1 = arima.sim(n = 120, list(ar = 0.8))
plot(y1, xlab = 't', ylab = 'y(t)', main = 'AR(1): y(t) = 0.8y(t - 1) + e(t)')
# Стационарные решения?
# Графически: более-менее постоянное матожидание, 
# дисперсия не зависит от t (не идет расширения/сужения "коридора"),
# ковариация между значениями с разным лагом также, судя по графику, постоянна, 
# поэтому, скорее всего, ряд стационарен.
# Проверим аналитически: для процесса AR(1) если коэффициент перед y(t - 1) 
# будет по модулю меньше 1, то ряд стационарен,
# здесь коэффициент равен 0.8, а значит, ряд действительно стационарен.

# AR(3):
y2 = arima.sim(n = 120, list(ar = c(0.1, 0.2, 0.3)))
plot(y2, xlab = 't', ylab = 'y(t)', 
     main = 'AR(3): y(t) = 0.1y(t - 1) + 0.2y(t - 2) + 0.3y(t - 3) + e(t)')
# Стационарные решения?
# Графически: те же самые суждения, что и для первого ряда => 
# скорее всего, этот ряд тоже стационарен.
# Проверим аналитически: (1 - 0.1B - 0.2B^2 - 0.3B^3) * y(t) = e(t),
# многочлен перед y(t) имеет корни: B1 = 1.23... 
# и комплексные B2,3 = -0.95... +/- 1.33...i, 
# abs(B1) = 1.23... > 1, 
# abs(B2,3) = sqrt(0.95...^2 + 1.33...^2) = 1.63... > 1,
# т.е. у этого многочлена нет корней, меньших или равных 1 по модулю => 
# ряд действительно стационарен.

# MA(2):
y3 = arima.sim(n = 120, list(ma = c(1.2, 2)))
plot(y3, xlab = 't', ylab = 'y(t)', main = 'MA(2): y(t) = e(t) + 1.2e(t - 1) + 2e(t - 2)')
# Стационарные решения?
# Процессы MA всегда стационарны, поэтому данный ряд стационарен. Это видно также графически.



## Задание 2

# На основе предыдущего пункта = используя те же коэффициенты для отдельных процессов AR и MA?

# ARIMA(0, 1, 2) = IMA(1, 2): разность y(t) первого порядка будет следовать процессу MA(2) 
y4 = arima.sim(n = 120, list(order = c(0, 1, 2), ma = c(1.2, 2)))
plot(y4, xlab = 't', ylab = 'y(t)', 
     main = 'ARIMA(0, 1, 2): y(t) - y(t - 1) = e(t) + 1.2e(t - 1) + 2e(t - 2)')
# Стационарные решения?
# Данный ряд не является стационарным. 
# Графически видно, что матожидание со временем меняется.
# Аналитически мы знаем, что процесс IMA будет стационарным в разностях, 
# но не стационарен сам по себе.

# ARIMA(0, 0, 0): обычный white noise
y5 = arima.sim(n = 120, list(order = c(0, 0, 0)))
plot(y5, xlab = 't', ylab = 'y(t)', main = 'ARIMA(0, 0, 0): y(t) = e(t)')
# Стационарные решения?
# Белый шум e(t) является стационарным по определению.

# ARIMA(3, 0, 0) = AR(3): аналогично ряду y2
y6 = arima.sim(n = 120, list(order = c(3, 0, 0), ar = c(0.1, 0.2, 0.3)))
plot(y6, xlab = 't', ylab = 'y(t)', 
     main = 'ARIMA(3, 0, 0): y(t) = 0.1y(t - 1) + 0.2y(t - 2) + 0.3y(t - 3) + e(t)')
# Стационарные решения?
# Аналогично процессу AR(3), который мы исследовали у y2, данный ряд является стационарным. 



## Задание 3

# Random walk without drift: y(t) = y(t - 1) + e(t)
y7 = arima.sim(n = 120, list(order = c(0, 1, 0)))
plot(y7, xlab = 't', ylab = 'y(t)', main = 'Random walk without drift: y(t) = y(t - 1) + e(t)')
# Стационарные решения?
# Случайное блуждание не является стационарным процессом; 
# графически видно, что матожидание изменяется со временем.



## Задание 4

# Таким рядом является ряд y1: y(t) = 0.8y(t - 1) + e(t).
acf(y1, main = 'AR(1): y(t) = 0.8y(t - 1) + e(t)')
pacf(y1, main = 'AR(1): y(t) = 0.8y(t - 1) + e(t)')
# Случайное блуждание задавалось рядом y7: y(t) = y(t - 1) + e(t).
acf(y7, main = 'Random walk without drift: y(t) = y(t - 1) + e(t)')
pacf(y7, main = 'Random walk without drift: y(t) = y(t - 1) + e(t)')

# Для обычного стационарного процесса AR(1), как и ожидается, ACF будет постепенно убывать
# и перестанет быть значимой на относительно высоких лагах, 
# а PACF обрывается на лаге, равном порядку процесса (в этом случае на лаге 1).
# Для случайного блуждания ACF гораздо дольше остается значимой,
# а PACF схожа с PACF процесса AR(1), ведь в некотором роде 
# случайное блуждание - это нестационарный AR(1).



## Задание 5

# Допустим, часть AR(2) будет задаваться коэффициентами -0.3 и 0.5, 
# а MA(3) -- коэффициентами 0.1, 0.1, 0.1.
# Генерируем временной ряд y8:
y8 = arima.sim(n = 120, list(order = c(2, 0, 3), ar = c(-0.3, 0.5), ma = c(0.1, 0.1, 0.1)))
plot(y8, xlab = 't', ylab = 'y(t)', main = 'ARIMA(2, 0, 3)')

# Первые 100 наблюдений оставляем в обучающую выборку, 
# а последние 20, которые будем предсказывать, - в тестовую:
ytrain = y8[1:100]
ytest = y8[101:120]

# Оцениваем модель ARIMA(2, 0, 3) на обучающей выборке:
ymod = arima(ytrain, order = c(2, 0, 3))

# Строим прогнозы в рамках 95%-ных доверительных интервалов на 20 периодов вперед: 
pred = predict(ymod, n.ahead = 20)
ypred = pred$pred
ylow = pred$pred - qnorm(0.975) * pred$se
yupp = pred$pred + qnorm(0.975) * pred$se

# Делаем визуальную оценку:
t = c(101:120)
plot(t, ytest, xlab = 't', ylab = 'y(t)', 
     main = 'ARIMA(2, 0, 3): real values, predictions and CI', 
     ylim = c(-30, 30))
lines(t, ypred, col = 'red')
lines(t, ylow, col = 'blue')
lines(t, yupp, col = 'blue')
legend(111, 30, legend = c('Real values', 'Predictions', 'Confidence intervals'), 
       col = c('black', 'red', 'blue'), lty = 1, cex = 0.8)
# Модель довольно хорошо предсказывает реальные значения: 
# все они оказались в границах доверительного интервала
# и в целом линия прогноза очень близка к тестовой выборке и отражает динамику развития.
